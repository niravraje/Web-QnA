{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of Words approach:\n",
    "\n",
    "The main advantage of the bag of words approach is that you do not need a very huge corpus of words to get good results. You can see that we build a very basic bag of words model with three sentences. Computationally, a bag of words model is not very complex.\n",
    "\n",
    "A major drawback of the bag of words approach is the fact that we need to create huge vectors with empty spaces in order to represent a number (sparse matrix) which consumes memory and space. In the example previous, we only had 3 sentences. Yet you can see three zeros in every vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import urllib.request\n",
    "import nltk\n",
    "import re\n",
    "import heapq\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_article_text(url):\n",
    "    # Scrape article using bs4 to extract all paragraphs from the online article.\n",
    "    raw_html = urllib.request.urlopen(url)\n",
    "    raw_html = raw_html.read()\n",
    "\n",
    "    article_html = BeautifulSoup(raw_html, 'lxml')\n",
    "    article_paragraphs = article_html.find_all('p')\n",
    "\n",
    "    # Creating a document 'article_text' containing all the sentences in the article.\n",
    "    article_text = ''\n",
    "    for para in article_paragraphs:\n",
    "        article_text += para.text\n",
    "    return article_text\n",
    "\n",
    "def remove_stopwords(sentence):\n",
    "    filtered_sentence = []\n",
    "    stop_words = nltk.corpus.stopwords.words('english')\n",
    "    word_tokens = nltk.word_tokenize(sentence)\n",
    "    for token in word_tokens:\n",
    "        if token not in stop_words:\n",
    "            filtered_sentence.append(token)\n",
    "    filtered_sentence = ' '.join(filtered_sentence)\n",
    "    return filtered_sentence\n",
    "\n",
    "def clean_sentence(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = remove_stopwords(sentence)\n",
    "    sentence = re.sub(r'\\W', ' ', sentence)\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    return sentence\n",
    "\n",
    "def clean_article_text(article_text):\n",
    "    # Creating a corpus containing all the sentence tokens in the document.\n",
    "    corpus = nltk.sent_tokenize(article_text)\n",
    "    # Convert to lowercase, remove non-word characters (punctuations, etc.) and strip whitespaces\n",
    "    for i in range(len(corpus)):\n",
    "        corpus[i] = clean_sentence(corpus[i])\n",
    "    return corpus\n",
    "\n",
    "def create_word_freq_dictionary(corpus):\n",
    "    # Create dictionary with word frequency\n",
    "    word_freq = defaultdict(int)\n",
    "    for sentence in corpus:\n",
    "        word_tokens = nltk.word_tokenize(sentence)\n",
    "        for token in word_tokens:\n",
    "            word_freq[token] += 1\n",
    "    return word_freq\n",
    "\n",
    "def generate_sent_vec(sentence, most_freq_tokens):\n",
    "    word_tokens = nltk.word_tokenize(sentence)\n",
    "    sent_vec = []\n",
    "    for token in most_freq_tokens:\n",
    "        if token in word_tokens:\n",
    "            sent_vec.append(1)\n",
    "        else:\n",
    "            sent_vec.append(0)\n",
    "    return sent_vec\n",
    "\n",
    "def get_sentence_vectors(corpus, most_freq_tokens):\n",
    "    # Generate sentence vectors of 1's and 0's. Feature set is the most_freq_tokens list.\n",
    "    sentence_vectors = []\n",
    "    for sentence in corpus:\n",
    "        sent_vec = generate_sent_vec(sentence, most_freq_tokens)\n",
    "        sentence_vectors.append(sent_vec)\n",
    "        \n",
    "    sentence_vectors = np.asarray(sentence_vectors)\n",
    "    return sentence_vectors\n",
    "\n",
    "def get_answer(url, question):\n",
    "\n",
    "    article_text = get_article_text(url)\n",
    "    #print(\"Article Text: \\n\", article_text)\n",
    "    initial_corpus = nltk.sent_tokenize(article_text)\n",
    "    corpus = clean_article_text(article_text)\n",
    "\n",
    "    word_freq = create_word_freq_dictionary(corpus)\n",
    "\n",
    "    # Get the most frequent tokens from the dictionary\n",
    "    most_freq_tokens = heapq.nlargest(200, word_freq, key=word_freq.get)\n",
    "\n",
    "    sentence_vectors = get_sentence_vectors(corpus, most_freq_tokens)\n",
    "\n",
    "    cleaned_question = clean_sentence(question)\n",
    "    question_vector = generate_sent_vec(cleaned_question, most_freq_tokens)\n",
    "\n",
    "    similarity_scores = []\n",
    "    sent_vec_index = 0\n",
    "    for sent_vec in sentence_vectors:\n",
    "        similarity = 1 - sp.spatial.distance.cosine(question_vector, sent_vec)\n",
    "        similarity_scores.append((sent_vec_index, similarity))\n",
    "        sent_vec_index += 1\n",
    "    similarity_scores.sort(key = lambda x: x[1], reverse=True)\n",
    "    answer_index = similarity_scores[0][0]\n",
    "\n",
    "    return initial_corpus[answer_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/India\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India's population grew from 361 million in 1951 to 1,211 million in 2011.\n"
     ]
    }
   ],
   "source": [
    "question = 'What is the population of India?'\n",
    "answer = get_answer(url, question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand and Indonesia.\n"
     ]
    }
   ],
   "source": [
    "question = 'Where is India located?'\n",
    "answer = get_answer(url, question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand and Indonesia.\n"
     ]
    }
   ],
   "source": [
    "question = 'Which countries are neighbouring to India?'\n",
    "answer = get_answer(url, question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand and Indonesia.\n"
     ]
    }
   ],
   "source": [
    "question = 'Who was the first Prime Minister of India?'\n",
    "answer = get_answer(url, question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55][56] The ancient Greeks referred to the Indians as Indoi (Ἰνδοί), which translates as \"The people of the Indus\".\n"
     ]
    }
   ],
   "source": [
    "question = 'What did ancient greeks refer to Indians as?'\n",
    "answer = get_answer(url, question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand and Indonesia.\n"
     ]
    }
   ],
   "source": [
    "question = 'Which sporting events has India hosted?'\n",
    "answer = get_answer(url, question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
