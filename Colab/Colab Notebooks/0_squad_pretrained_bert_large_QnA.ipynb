{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"0_squad_pretrained_bert_large_QnA.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1eFFofUFteVb96QccmbzkL1ojSltHmmZ9","authorship_tag":"ABX9TyNcWm1KX3ZnuWnai53pykns"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"_xL40VkQJdNv","colab_type":"text"},"source":["**Purpose:**\n","\n","Since the max sequence length for a BERT model is 512 tokens, this script uses the *generate_context()* function from *infersent_glove_context_generation.py*. \n","\n","*generate_context()* takes the URL and the question, and finds the N most similar sentences on that web page. It concatenates them and returns a context of valid sequence length.\n","\n","This context and the question are then fed to the BERT QnA model to extract the answer."]},{"cell_type":"code","metadata":{"id":"zOHeTqjGY1u1","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R3vpKFKIFcu5","colab_type":"code","colab":{}},"source":["!pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3yfnJIQkaEQg","colab_type":"code","colab":{}},"source":["#!wget --directory-prefix='/content/drive/My Drive/colab_files/word_embeddings/' http://nlp.stanford.edu/data/glove.6B.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"etdFHZbTnoqL","colab_type":"code","colab":{}},"source":["#!wget --directory-prefix='/content/drive/My Drive/colab_files/InferSent/encoder/' https://dl.fbaipublicfiles.com/infersent/infersent1.pkl"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M0QQ_q3Qk51v","colab_type":"code","colab":{}},"source":["#import zipfile\n","#with zipfile.ZipFile('/content/drive/My Drive/colab_files/word_embeddings/glove.6B.zip', 'r') as zip_ref:\n","#    zip_ref.extractall('/content/drive/My Drive/colab_files/word_embeddings/glove/')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wxE3d-gfstuF","colab_type":"code","colab":{}},"source":["import sys\n","sys.path.append('/content/drive/My Drive/colab_files/modules')\n","\n","import infersent_glove_context_generation as ig\n","\n","import time\n","import os\n","import contextlib\n","import torch\n","import nltk\n","nltk.download('punkt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GcEs7yce17QL","colab_type":"code","colab":{}},"source":["from transformers import BertForQuestionAnswering\n","model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n","\n","from transformers import BertTokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fzz4gRuH1jlC","colab_type":"code","colab":{}},"source":["def extract_answer_phrase(question, context):\n","    '''\n","    Takes a `question` string and an `context` string (which contains the\n","    answer), and identifies the words within the `context` that are the\n","    answer. Prints them out.\n","    '''\n","    # Apply the tokenizer to the input text, treating them as a text-pair.\n","    input_ids = tokenizer.encode(question, context)\n","\n","    # Report how long the input sequence is.\n","    print('Query has {:,} tokens.\\n'.format(len(input_ids)))\n","\n","    # ======== Set Segment IDs ========\n","    # Search the input_ids for the first instance of the `[SEP]` token.\n","    sep_index = input_ids.index(tokenizer.sep_token_id)\n","\n","    # The number of segment A tokens includes the [SEP] token istelf.\n","    num_seg_a = sep_index + 1\n","\n","    # The remainder are segment B.\n","    num_seg_b = len(input_ids) - num_seg_a\n","\n","    # Construct the list of 0s and 1s.\n","    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n","\n","    # There should be a segment_id for every input token.\n","    assert len(segment_ids) == len(input_ids)\n","\n","    # ======== Evaluate ========\n","    # Run our example question through the model.\n","    start_scores, end_scores = model(torch.tensor([input_ids]), # The tokens representing our input text.\n","                                    token_type_ids=torch.tensor([segment_ids])) # The segment IDs to differentiate question from answer_text\n","\n","    # ======== Reconstruct Answer ========\n","    # Find the tokens with the highest `start` and `end` scores.\n","    answer_start = torch.argmax(start_scores)\n","    answer_end = torch.argmax(end_scores)\n","\n","    # Get the string versions of the input tokens.\n","    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n","\n","    # Start with the first token.\n","    answer = tokens[answer_start]\n","\n","    # Select the remaining answer tokens and join them with whitespace.\n","    for i in range(answer_start + 1, answer_end + 1):\n","        \n","        # If it's a subword token, then recombine it with the previous token.\n","        if tokens[i][0:2] == '##':\n","            answer += tokens[i][2:]\n","        \n","        # Otherwise, add a space then the token.\n","        else:\n","            answer += ' ' + tokens[i]\n","\n","    #print('Answer: \"' + answer + '\"')\n","    return answer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5RUi4sY74Oih","colab_type":"code","colab":{}},"source":["def find_answer(url, question):\n","    context = ig.generate_context(url, question)\n","    answer = extract_answer_phrase(question, context)\n","    return answer"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bAnqRRAATvAJ","colab_type":"text"},"source":["**Inference:**"]},{"cell_type":"code","metadata":{"id":"7c7c3-fCqmn_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":112},"executionInfo":{"status":"ok","timestamp":1600415421030,"user_tz":-330,"elapsed":29139,"user":{"displayName":"Nirav Raje","photoUrl":"https://lh6.googleusercontent.com/-rwxb81DyHSk/AAAAAAAAAAI/AAAAAAAABco/BzjCAyIBALo/s64/photo.jpg","userId":"10387550002262274732"}},"outputId":"286c5b5f-c97e-49fd-d5e0-dfa21c28094a"},"source":["url = 'https://en.wikipedia.org/wiki/India'\n","question = 'Which sports does India play?'\n","\n","start_time = time.time()\n","with open(os.devnull, \"w\") as f, contextlib.redirect_stdout(f):\n","    answer = find_answer(url, question)\n","end_time = time.time()\n","print('Answer: ', answer)\n","print('\\n\\nTotal Execution Time: {} seconds'.format(end_time - start_time))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Answer:  cricket is the most popular sport in india . in india , several traditional indigenous sports remain fairly popular , such as kabaddi , kho kho , pehlwani and gilli - danda . india has traditionally been the dominant country at the south asian games . corruption in india is perceived to have decreased . other sports in which indians have succeeded internationally include badminton ( saina nehwal and p v sindhu are two of the top - ranked female badminton players in the world ) , boxing , and wrestling\n","\n","\n","Total Execution Time: 27.443676710128784 seconds\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SBwaqXJBMC-s","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":261},"executionInfo":{"status":"ok","timestamp":1600415714148,"user_tz":-330,"elapsed":22344,"user":{"displayName":"Nirav Raje","photoUrl":"https://lh6.googleusercontent.com/-rwxb81DyHSk/AAAAAAAAAAI/AAAAAAAABco/BzjCAyIBALo/s64/photo.jpg","userId":"10387550002262274732"}},"outputId":"68ca61f8-0a46-4e35-a105-4b5651dfd04e"},"source":["url = 'https://en.wikipedia.org/wiki/Cryptocurrency'\n","question = 'Who launched the first Bitcoin ATM?'\n","\n","start_time = time.time()\n","with open(os.devnull, \"w\") as f, contextlib.redirect_stdout(f):\n","    answer = find_answer(url, question)\n","end_time = time.time()\n","print('\\n\\nAnswer: ', answer)\n","print('\\n\\nTotal Execution Time: {} seconds'.format(end_time - start_time))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', '46,', 'Issue', '4).', '</s>']\" (idx=11) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', '[unreliable', 'source?]', '</s>']\" (idx=175) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', '</s>']\" (idx=206) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n"],"name":"stderr"},{"output_type":"stream","text":["\n","\n","Answer:  jordan kelley\n","\n","\n","Total Execution Time: 20.821406841278076 seconds\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HxQ1RXcgMC36","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G5Mabk2_MCxf","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}