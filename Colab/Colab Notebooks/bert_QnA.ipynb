{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bert_QnA.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1eFFofUFteVb96QccmbzkL1ojSltHmmZ9","authorship_tag":"ABX9TyPIX0EOh8qn43u+RU1HSsgW"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"zOHeTqjGY1u1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1598788802800,"user_tz":-330,"elapsed":3591,"user":{"displayName":"Nirav Raje","photoUrl":"https://lh6.googleusercontent.com/-rwxb81DyHSk/AAAAAAAAAAI/AAAAAAAABco/BzjCAyIBALo/s64/photo.jpg","userId":"10387550002262274732"}},"outputId":"d76fea01-2702-496a-ef59-f05d88e740b0"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"R3vpKFKIFcu5","colab_type":"code","colab":{}},"source":["!pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3yfnJIQkaEQg","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598788805801,"user_tz":-330,"elapsed":6574,"user":{"displayName":"Nirav Raje","photoUrl":"https://lh6.googleusercontent.com/-rwxb81DyHSk/AAAAAAAAAAI/AAAAAAAABco/BzjCAyIBALo/s64/photo.jpg","userId":"10387550002262274732"}}},"source":["#!wget --directory-prefix='/content/drive/My Drive/colab_files/word_embeddings/' http://nlp.stanford.edu/data/glove.6B.zip"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"etdFHZbTnoqL","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598788805805,"user_tz":-330,"elapsed":6572,"user":{"displayName":"Nirav Raje","photoUrl":"https://lh6.googleusercontent.com/-rwxb81DyHSk/AAAAAAAAAAI/AAAAAAAABco/BzjCAyIBALo/s64/photo.jpg","userId":"10387550002262274732"}}},"source":["#!wget --directory-prefix='/content/drive/My Drive/colab_files/InferSent/encoder/' https://dl.fbaipublicfiles.com/infersent/infersent1.pkl"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"M0QQ_q3Qk51v","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598788805810,"user_tz":-330,"elapsed":6571,"user":{"displayName":"Nirav Raje","photoUrl":"https://lh6.googleusercontent.com/-rwxb81DyHSk/AAAAAAAAAAI/AAAAAAAABco/BzjCAyIBALo/s64/photo.jpg","userId":"10387550002262274732"}}},"source":["#import zipfile\n","#with zipfile.ZipFile('/content/drive/My Drive/colab_files/word_embeddings/glove.6B.zip', 'r') as zip_ref:\n","#    zip_ref.extractall('/content/drive/My Drive/colab_files/word_embeddings/glove/')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"wxE3d-gfstuF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":110},"executionInfo":{"status":"ok","timestamp":1598788807663,"user_tz":-330,"elapsed":8419,"user":{"displayName":"Nirav Raje","photoUrl":"https://lh6.googleusercontent.com/-rwxb81DyHSk/AAAAAAAAAAI/AAAAAAAABco/BzjCAyIBALo/s64/photo.jpg","userId":"10387550002262274732"}},"outputId":"099c4d18-cde9-4b8d-9506-c33750cffdaa"},"source":["import sys\n","sys.path.append('/content/drive/My Drive/colab_files/modules')\n","\n","import infersent_glove_context_generation as ig\n","\n","import time\n","import os\n","import contextlib\n","import torch\n","import nltk\n","nltk.download('punkt')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"GcEs7yce17QL","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598788822811,"user_tz":-330,"elapsed":23562,"user":{"displayName":"Nirav Raje","photoUrl":"https://lh6.googleusercontent.com/-rwxb81DyHSk/AAAAAAAAAAI/AAAAAAAABco/BzjCAyIBALo/s64/photo.jpg","userId":"10387550002262274732"}}},"source":["from transformers import BertForQuestionAnswering\n","model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n","\n","from transformers import BertTokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fzz4gRuH1jlC","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598788881821,"user_tz":-330,"elapsed":2113,"user":{"displayName":"Nirav Raje","photoUrl":"https://lh6.googleusercontent.com/-rwxb81DyHSk/AAAAAAAAAAI/AAAAAAAABco/BzjCAyIBALo/s64/photo.jpg","userId":"10387550002262274732"}}},"source":["def extract_answer_phrase(question, context):\n","    '''\n","    Takes a `question` string and an `context` string (which contains the\n","    answer), and identifies the words within the `context` that are the\n","    answer. Prints them out.\n","    '''\n","    # ======== Tokenize ========\n","    # Apply the tokenizer to the input text, treating them as a text-pair.\n","    input_ids = tokenizer.encode(question, context)\n","\n","    # Report how long the input sequence is.\n","    print('Query has {:,} tokens.\\n'.format(len(input_ids)))\n","\n","    # ======== Set Segment IDs ========\n","    # Search the input_ids for the first instance of the `[SEP]` token.\n","    sep_index = input_ids.index(tokenizer.sep_token_id)\n","\n","    # The number of segment A tokens includes the [SEP] token istelf.\n","    num_seg_a = sep_index + 1\n","\n","    # The remainder are segment B.\n","    num_seg_b = len(input_ids) - num_seg_a\n","\n","    # Construct the list of 0s and 1s.\n","    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n","\n","    # There should be a segment_id for every input token.\n","    assert len(segment_ids) == len(input_ids)\n","\n","    # ======== Evaluate ========\n","    # Run our example question through the model.\n","    start_scores, end_scores = model(torch.tensor([input_ids]), # The tokens representing our input text.\n","                                    token_type_ids=torch.tensor([segment_ids])) # The segment IDs to differentiate question from answer_text\n","\n","    # ======== Reconstruct Answer ========\n","    # Find the tokens with the highest `start` and `end` scores.\n","    answer_start = torch.argmax(start_scores)\n","    answer_end = torch.argmax(end_scores)\n","\n","    # Get the string versions of the input tokens.\n","    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n","\n","    # Start with the first token.\n","    answer = tokens[answer_start]\n","\n","    # Select the remaining answer tokens and join them with whitespace.\n","    for i in range(answer_start + 1, answer_end + 1):\n","        \n","        # If it's a subword token, then recombine it with the previous token.\n","        if tokens[i][0:2] == '##':\n","            answer += tokens[i][2:]\n","        \n","        # Otherwise, add a space then the token.\n","        else:\n","            answer += ' ' + tokens[i]\n","\n","    #print('Answer: \"' + answer + '\"')\n","    return answer"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"5RUi4sY74Oih","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598788882901,"user_tz":-330,"elapsed":2626,"user":{"displayName":"Nirav Raje","photoUrl":"https://lh6.googleusercontent.com/-rwxb81DyHSk/AAAAAAAAAAI/AAAAAAAABco/BzjCAyIBALo/s64/photo.jpg","userId":"10387550002262274732"}}},"source":["def find_answer(url, question):\n","    context = ig.generate_context(url, question)\n","    answer = extract_answer_phrase(question, context)\n","    return answer"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bAnqRRAATvAJ","colab_type":"text"},"source":["**Evaluate:**"]},{"cell_type":"code","metadata":{"id":"7c7c3-fCqmn_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598788928508,"user_tz":-330,"elapsed":1803,"user":{"displayName":"Nirav Raje","photoUrl":"https://lh6.googleusercontent.com/-rwxb81DyHSk/AAAAAAAAAAI/AAAAAAAABco/BzjCAyIBALo/s64/photo.jpg","userId":"10387550002262274732"}}},"source":["url = 'https://en.wikipedia.org/wiki/India'\n","question = 'Which sports does India play?'"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"a6knyQdWqMZR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":111},"executionInfo":{"status":"ok","timestamp":1598789157010,"user_tz":-330,"elapsed":29593,"user":{"displayName":"Nirav Raje","photoUrl":"https://lh6.googleusercontent.com/-rwxb81DyHSk/AAAAAAAAAAI/AAAAAAAABco/BzjCAyIBALo/s64/photo.jpg","userId":"10387550002262274732"}},"outputId":"9adfd260-3a7d-411d-9e42-8338c4215b24"},"source":["start_time = time.time()\n","with open(os.devnull, \"w\") as f, contextlib.redirect_stdout(f):\n","    answer = find_answer(url, question)\n","end_time = time.time()\n","print('Answer: ', answer)\n","print('\\n\\nExecution Time: {} seconds'.format(end_time - start_time))"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Answer:  cricket is the most popular sport in india . other sports in which indians have succeeded internationally include badminton ( saina nehwal and p v sindhu are two of the top - ranked female badminton players in the world ) , boxing , and wrestling\n","\n","\n","Execution Time: 27.999518394470215 seconds\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GcmusUKe-Kaw","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1598788846737,"user_tz":-330,"elapsed":47457,"user":{"displayName":"Nirav Raje","photoUrl":"https://lh6.googleusercontent.com/-rwxb81DyHSk/AAAAAAAAAAI/AAAAAAAABco/BzjCAyIBALo/s64/photo.jpg","userId":"10387550002262274732"}}},"source":[""],"execution_count":null,"outputs":[]}]}