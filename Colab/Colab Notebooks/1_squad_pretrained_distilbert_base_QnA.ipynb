{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1_squad_pretrained_distilbert_base_QnA.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"oFm4G089Nm2w","colab_type":"text"},"source":["**Purpose:**\n","\n","Inference with a DistilBERT model pretrained on SQuAD\n"]},{"cell_type":"code","metadata":{"id":"xoqgLwZoH9rA","colab_type":"code","colab":{}},"source":["%%capture\n","!pip install transformers\n","\n","import time\n","import sys\n","import os\n","import contextlib\n","\n","from transformers import DistilBertTokenizer, DistilBertForQuestionAnswering\n","import torch\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nlet4Uw_8-Ex","colab_type":"code","colab":{}},"source":["tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', return_token_type_ids = True)\n","model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased-distilled-squad')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tSUGA0_p8-Fn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":185},"executionInfo":{"status":"ok","timestamp":1600671738372,"user_tz":-330,"elapsed":8553,"user":{"displayName":"Nirav Raje","photoUrl":"https://lh6.googleusercontent.com/-rwxb81DyHSk/AAAAAAAAAAI/AAAAAAAABco/BzjCAyIBALo/s64/photo.jpg","userId":"10387550002262274732"}},"outputId":"a0cc161f-5ec0-49d8-8a6f-9a9b4bf5aa2a"},"source":["# Inference:\n","\n","start_time = time.time()\n","context = \"The US has passed the peak on new coronavirus cases, \" \\\n","          \"President Donald Trump said and predicted that some states would reopen this month. \" \\\n","          \"The US has over 637,000 confirmed Covid-19 cases and over 30,826 deaths, the highest for any country in the world.\"\n","\n","question = \"What was President Donald Trump's prediction?\"\n","\n","encoding = tokenizer.encode_plus(question, context)\n","\n","\n","input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n","\n","start_scores, end_scores = model(torch.tensor([input_ids]), attention_mask=torch.tensor([attention_mask]))\n","\n","ans_tokens = input_ids[torch.argmax(start_scores) : torch.argmax(end_scores)+1]\n","answer_tokens = tokenizer.convert_ids_to_tokens(ans_tokens , skip_special_tokens=True)\n","\n","print (\"\\nQuestion \",question)\n","print (\"\\nAnswer Tokens: \")\n","print (answer_tokens)\n","\n","answer_tokens_to_string = tokenizer.convert_tokens_to_string(answer_tokens)\n","\n","print (\"\\nAnswer : \",answer_tokens_to_string)\n","\n","end_time = time.time()\n","\n","print(\"\\nExecution Time: {} seconds.\".format(end_time - start_time))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Question  What was President Donald Trump's prediction?\n","\n","Answer Tokens: \n","['some', 'states', 'would', 're', '##open', 'this', 'month']\n","\n","Answer :  some states would reopen this month\n","\n","Execution Time: 0.13521170616149902 seconds.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bE66c7S_8-Fr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1600671740162,"user_tz":-330,"elapsed":10337,"user":{"displayName":"Nirav Raje","photoUrl":"https://lh6.googleusercontent.com/-rwxb81DyHSk/AAAAAAAAAAI/AAAAAAAABco/BzjCAyIBALo/s64/photo.jpg","userId":"10387550002262274732"}},"outputId":"313d423f-ffdc-49aa-9fe7-4a27a29fea29"},"source":["from transformers.data.processors.squad import SquadV2Processor\n","\n","# this processor loads the SQuAD2.0 dev set examples\n","processor = SquadV2Processor()\n","examples = processor.get_dev_examples(\"/content/drive/My Drive/colab_files/data/Covid-QA/\", filename=\"Covid-QA-val.json\")\n","print(len(examples))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 29/29 [00:01<00:00, 15.12it/s]"],"name":"stderr"},{"output_type":"stream","text":["215\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GcmusUKe-Kaw","colab":{}},"source":["# generate some maps to help us identify examples of interest\n","qid_to_example_index = {example.qas_id: i for i, example in enumerate(examples)}\n","qid_to_has_answer = {example.qas_id: bool(example.answers) for example in examples}\n","answer_qids = [qas_id for qas_id, has_answer in qid_to_has_answer.items() if has_answer]\n","no_answer_qids = [qas_id for qas_id, has_answer in qid_to_has_answer.items() if not has_answer]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7kv4uLpiSjqe","colab_type":"code","colab":{}},"source":["def display_example(qid):    \n","    from pprint import pprint\n","\n","    idx = qid_to_example_index[qid]\n","    q = examples[idx].question_text\n","    c = examples[idx].context_text\n","    a = [answer['text'] for answer in examples[idx].answers]\n","    \n","    print(f'Example {idx} of {len(examples)}\\n---------------------')\n","    print(f\"Q: {q}\\n\")\n","    print(\"Context:\")\n","    pprint(c)\n","    print(f\"\\nTrue Answers:\\n{a}\")\n","\n","#display_example(answer_qids[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OYaJVsDVSlNb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":111},"executionInfo":{"status":"ok","timestamp":1600671741380,"user_tz":-330,"elapsed":11539,"user":{"displayName":"Nirav Raje","photoUrl":"https://lh6.googleusercontent.com/-rwxb81DyHSk/AAAAAAAAAAI/AAAAAAAABco/BzjCAyIBALo/s64/photo.jpg","userId":"10387550002262274732"}},"outputId":"fab6369f-ef0c-4cd1-9d9b-10dadc4bb560"},"source":["import sys\n","sys.path.append('/content/drive/My Drive/colab_files/modules')\n","\n","import infersent_glove_context_generation as ig\n","\n","import time\n","import os\n","import contextlib\n","import torch\n","import nltk\n","nltk.download('punkt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"NDLZS3klSpC-","colab_type":"code","colab":{}},"source":["def get_prediction(qid):\n","    # given a question id (qas_id or qid), load the example, get the model outputs and generate an answer\n","    question = examples[qid_to_example_index[qid]].question_text\n","    doc_text = examples[qid_to_example_index[qid]].context_text\n","\n","    with open(os.devnull, \"w\") as f, contextlib.redirect_stdout(f):\n","        context = ig.generate_context_from_doc(doc_text, question)\n","    context_tokens = nltk.word_tokenize(context)\n","    #print('\\nContext token count: ', len(context_tokens))\n","    #print('\\n\\nContext tokens: ', context_tokens)\n","\n","    inputs = tokenizer.encode_plus(question, context, return_tensors='pt')\n","\n","    outputs = model(**inputs)\n","    answer_start = torch.argmax(outputs[0])  # get the most likely beginning of answer with the argmax of the score\n","    answer_end = torch.argmax(outputs[1]) + 1 \n","\n","    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n","\n","    return answer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zXmIaypvSqqv","colab_type":"code","colab":{}},"source":["# these functions are heavily influenced by the HF squad_metrics.py script\n","def normalize_text(s):\n","    \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n","    import string, re\n","\n","    def remove_articles(text):\n","        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n","        return re.sub(regex, \" \", text)\n","\n","    def white_space_fix(text):\n","        return \" \".join(text.split())\n","\n","    def remove_punc(text):\n","        exclude = set(string.punctuation)\n","        return \"\".join(ch for ch in text if ch not in exclude)\n","\n","    def lower(text):\n","        return text.lower()\n","\n","    return white_space_fix(remove_articles(remove_punc(lower(s))))\n","\n","def compute_exact_match(prediction, truth):\n","    return int(normalize_text(prediction) == normalize_text(truth))\n","\n","def compute_f1(prediction, truth):\n","    pred_tokens = normalize_text(prediction).split()\n","    truth_tokens = normalize_text(truth).split()\n","    \n","    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n","    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n","        return int(pred_tokens == truth_tokens)\n","    \n","    common_tokens = set(pred_tokens) & set(truth_tokens)\n","    \n","    # if there are no common tokens then f1 = 0\n","    if len(common_tokens) == 0:\n","        return 0\n","    \n","    prec = len(common_tokens) / len(pred_tokens)\n","    rec = len(common_tokens) / len(truth_tokens)\n","    \n","    return 2 * (prec * rec) / (prec + rec)\n","\n","def get_gold_answers(example):\n","    \"\"\"helper function that retrieves all possible true answers from a squad2.0 example\"\"\"\n","    \n","    gold_answers = [answer[\"text\"] for answer in example.answers if answer[\"text\"]]\n","\n","    # if gold_answers doesn't exist it's because this is a negative example - \n","    # the only correct answer is an empty string\n","    if not gold_answers:\n","        gold_answers = [\"\"]\n","        \n","    return gold_answers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LVxQmopLUX2J","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1600671741385,"user_tz":-330,"elapsed":11520,"user":{"displayName":"Nirav Raje","photoUrl":"https://lh6.googleusercontent.com/-rwxb81DyHSk/AAAAAAAAAAI/AAAAAAAABco/BzjCAyIBALo/s64/photo.jpg","userId":"10387550002262274732"}},"outputId":"86e3c1a4-2c28-4495-a876-e2572400c54d"},"source":["answer_qids[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5232"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"OdkCpkScSsHW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":129},"executionInfo":{"status":"ok","timestamp":1600671751927,"user_tz":-330,"elapsed":22056,"user":{"displayName":"Nirav Raje","photoUrl":"https://lh6.googleusercontent.com/-rwxb81DyHSk/AAAAAAAAAAI/AAAAAAAABco/BzjCAyIBALo/s64/photo.jpg","userId":"10387550002262274732"}},"outputId":"52e80a7f-f2a7-4026-fcf3-3be39fb47c12"},"source":["start_time = time.time()\n","prediction = get_prediction(answer_qids[0])\n","example = examples[qid_to_example_index[answer_qids[0]]]\n","\n","gold_answers = get_gold_answers(example)\n","\n","em_score = max((compute_exact_match(prediction, answer)) for answer in gold_answers)\n","f1_score = max((compute_f1(prediction, answer)) for answer in gold_answers)\n","\n","print(f\"Question: {example.question_text}\")\n","print(f\"Prediction: {prediction}\")\n","print(f\"True Answers: {gold_answers}\")\n","print(f\"EM: {em_score} \\t F1: {f1_score}\")\n","\n","print(\"\\nExecution time: {}\".format(time.time() - start_time))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Question: Why are nucleosides analogs used for chemotheraphy?\n","Prediction: they inhibit cellular dna / rna polymerases\n","True Answers: ['they inhibit cellular DNA/RNA polymerases']\n","EM: 0 \t F1: 0.7272727272727272\n","\n","Execution time: 10.858467817306519\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Bn-gVoHUStk1","colab_type":"code","colab":{}},"source":["def evaluate_model():\n","    em_scores = []\n","    f1_scores = []\n","\n","    for qid in answer_qids:\n","        prediction = get_prediction(qid)\n","        example = examples[qid_to_example_index[qid]]\n","        gold_answers = get_gold_answers(example)\n","        em_score = max((compute_exact_match(prediction, answer)) for answer in gold_answers)\n","        f1_score = max((compute_f1(prediction, answer)) for answer in gold_answers)\n","\n","        em_scores.append(em_score)\n","        f1_scores.append(f1_score)\n","\n","    avg_em = sum(em_scores) / len(em_scores)\n","    avg_f1 = sum(f1_scores) / len(f1_scores)\n","\n","    print(\"\\nAvg EM: {}\".format(avg_em))\n","    print(\"\\nAvg F1: {}\".format(avg_f1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tDxsan4CS51f","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1600673978631,"user_tz":-330,"elapsed":2248750,"user":{"displayName":"Nirav Raje","photoUrl":"https://lh6.googleusercontent.com/-rwxb81DyHSk/AAAAAAAAAAI/AAAAAAAABco/BzjCAyIBALo/s64/photo.jpg","userId":"10387550002262274732"}},"outputId":"944dcf4e-7fe4-45e6-e91c-3ab1971ce8a0"},"source":["start_time = time.time()\n","evaluate_model()\n","print(\"\\n\\nExecution time: {}\".format(time.time() - start_time))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'No.', '</s>']\" (idx=23) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', '258/11_120365).', '</s>']\" (idx=24) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', '.newer', 'organizations.\"', '</s>']\" (idx=21) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'Is', 'hepcidin', 'toxic?', '</s>']\" (idx=0) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'Scheme', '1.', '</s>']\" (idx=21) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'Scheme', '1.', '</s>']\" (idx=32) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'Scheme', '1.', '</s>']\" (idx=37) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'Anal.', '</s>']\" (idx=95) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'Calcd.', '</s>']\" (idx=96) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', '3-Methyl-2-vinylquinazolin-4(3H)-one', '(13j).', '</s>']\" (idx=101) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'Diethyl', 'trans-(2-methyl-5-(4-oxo-3,4-dihydroquinazolin-2-yl)isoxazolidin-3-yl)phosphonate', '(trans-11a).', '</s>']\" (idx=107) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'References', '1.', '</s>']\" (idx=48) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'Swerdlow', 'DL,', 'Finelli', 'L,', 'Bridges', 'CB.', '</s>']\" (idx=49) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'Clin', 'Infect', 'Dis.', '</s>']\" (idx=51) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', '2011;52(suppl', '1):S1-S3.', '</s>']\" (idx=52) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'doi:10.1093/cid/ciq005PubMedGoogle', 'ScholarCrossref', '2.', '</s>']\" (idx=53) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'BMC', 'Medicine.', '</s>']\" (idx=56) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', '2009;7(45).', '</s>']\" (idx=57) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'doi:10.1186/1741-7015-7-45', '3.', '</s>']\" (idx=58) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'Lancet', 'Infect', 'Dis.', '</s>']\" (idx=61) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', '2012;12(9):687-695.', 'doi:10.1016/S1473-3099(12)70121-4PubMedGoogle', 'ScholarCrossref', '4.', '</s>']\" (idx=62) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'Chowell', 'G,', 'Castillo-Chavez', 'C,', 'Fenimore', 'PW,', 'Kribs-Zaleta', 'CM,', 'Arriola', 'L,', 'Hyman', 'JM.', '</s>']\" (idx=63) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'Emerg', 'Infect', 'Dis.', '</s>']\" (idx=65) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', '2004;10(7):1258-1263.', 'doi:10.3201/eid1007.030647PubMedGoogle', 'ScholarCrossref', '5.', '</s>']\" (idx=66) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'Killerby', 'ME,', 'Biggs', 'HM,', 'Midgley', 'CM,', 'Gerber', 'SI,', 'Watson', 'JT.', '</s>']\" (idx=67) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'Emerg', 'Infect', 'Dis.', '</s>']\" (idx=69) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', '2020;26(2):191-198.', 'doi:10.3201/eid2602.190697PubMedGoogle', 'ScholarCrossref', '6.', '</s>']\" (idx=70) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'Rasmussen', 'SA,', 'Watson', 'AK,', 'Swerdlow', 'DL.', '</s>']\" (idx=71) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'Microbiol', 'Spectr.', '</s>']\" (idx=73) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', '2016;4(3).', '</s>']\" (idx=74) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'doi:10.1128/microbiolspec.EI10-0020-2016PubMedGoogle', 'Scholar', '7.', '</s>']\" (idx=75) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'Clin', 'Infect', 'Dis.', '</s>']\" (idx=78) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', '2015;60(suppl):S1-S63.', '</s>']\" (idx=79) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'https://academic.oup.com/cid/issue/60/suppl_1.Google', 'Scholar', '8.', '</s>']\" (idx=80) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'JAMA.', '</s>']\" (idx=83) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'N', 'Engl', 'J', 'Med.', '</s>']\" (idx=87) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'World', 'Health', 'Organization.', '</s>']\" (idx=89) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'https://www.who.int/emergencies/diseases/novel-coronavirus-2019/situation-reports/.', '</s>']\" (idx=91) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'Accessed', 'February', '4,', '2020.', '</s>']\" (idx=92) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'REFERENCE', '1.', '</s>']\" (idx=119) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'All', 'Rights', 'Reserved.', '</s>']\" (idx=122) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'Virus.', '</s>']\" (idx=29) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'Yunnan', 'province,', 'China.', '</s>']\" (idx=39) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'Vitro.', '</s>']\" (idx=50) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'Assay.', '</s>']\" (idx=54) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', '2.6.', '</s>']\" (idx=61) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'Plaque', 'Assay.', '</s>']\" (idx=62) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', '2.8.', '</s>']\" (idx=74) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'ELISA.', '</s>']\" (idx=75) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', '2.10.', '</s>']\" (idx=79) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'Statistical', 'Analysis.', '</s>']\" (idx=80) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', '6-month-old', 'infant.', '</s>']\" (idx=72) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'Technique.', '</s>']\" (idx=52) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'Figure', '3A', ').', '</s>']\" (idx=123) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'Accession', 'number(s).', '</s>']\" (idx=30) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'N', 'http://www.organic-chemistry.org.', '</s>']\" (idx=47) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'N', 'http://mobyle.rpbs.univ-paris-diderot.fr/cgi-bin/portal.', '</s>']\" (idx=48) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'py?', '</s>']\" (idx=49) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', '(DOC)', '</s>']\" (idx=141) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'HM245923).', '</s>']\" (idx=16) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'EU714029).', '</s>']\" (idx=20) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n","/content/drive/My Drive/colab_files/modules/models_infersent.py:197: UserWarning: No words in \"['<s>', 'DQ288927.', '</s>']\" (idx=29) have w2v vectors.                                Replacing by \"</s>\"..\n","  Replacing by \"</s>\"..' % (sentences[i], i))\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Avg EM: 0.16279069767441862\n","\n","Avg F1: 0.294424725711961\n","\n","\n","Execution time: 2226.6570670604706\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"syeyRedBm4nt","colab_type":"text"},"source":["Avg EM: 0.16279069767441862\n","\n","Avg F1: 0.294424725711961\n","\n","Execution time: 2226.6570670604706"]}]}