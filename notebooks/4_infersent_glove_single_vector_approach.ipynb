{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import time\n",
    "import string\n",
    "import math\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import urllib.request\n",
    "import nltk\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import sys\n",
    "sys.path.append('C:/Users/niraje/Documents/MLG/Web-QnA/modules')\n",
    "import models_infersent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    \"\"\"Convert each sentence into lower case. \n",
    "    Extract English alphabets.\n",
    "    Remove extra spaces.\n",
    "    Strip leading/trailing whitespaces.\n",
    "    \"\"\"\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(r'[^A-Za-z]', ' ', sentence)\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch the article text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/India'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape article using bs4 to extract all paragraphs from the online article.\n",
    "raw_html = urllib.request.urlopen(url)\n",
    "raw_html = raw_html.read()\n",
    "\n",
    "article_html = BeautifulSoup(raw_html, 'lxml')\n",
    "article_paragraphs = article_html.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a document 'article_text' containing all the sentences in the article.\n",
    "article_text = ''\n",
    "for para in article_paragraphs:\n",
    "    article_text += para.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize article text into sentences.\n",
    "article_sentences = nltk.sent_tokenize(article_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess sentences for InferSent encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['India (Hindi: Bhārat), officially the Republic of India (Hindi: Bhārat Gaṇarājya), is a country in South Asia.',\n",
       " 'It is the second-most populous country, the seventh-largest country by land area, and the most populous democracy in the world.',\n",
       " 'Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west; China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east.',\n",
       " 'In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand and Indonesia.',\n",
       " 'Modern humans arrived on the Indian subcontinent from Africa no later than 55,000 years ago.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the article sentence to remove extra whitespaces and reference numbers (such as \"[23]\")\n",
    "\n",
    "for i in range(len(article_sentences)):\n",
    "    article_sentences[i] = re.sub(r'\\[\\d+\\]', '', article_sentences[i])\n",
    "    article_sentences[i] = re.sub(r'\\[\\w\\]', '', article_sentences[i])\n",
    "    article_sentences[i] = re.sub(r'\\s+', ' ', article_sentences[i]).strip()\n",
    "article_sentences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of InferSent Sentence Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import stuff\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from random import randint\n",
    "\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model:\n",
    "Load infersent model (version 1) which has been trained on GloVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "from models_infersent import InferSent\n",
    "model_version = 1\n",
    "MODEL_PATH = \"../../InferSent/encoder/infersent%s.pkl\" % model_version\n",
    "params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
    "                'pool_type': 'max', 'dpout_model': 0.0, 'version': model_version}\n",
    "model = InferSent(params_model)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the GloVe directory path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2V_PATH = '../../word_vectors/glove/glove.6B.300d.txt'\n",
    "model.set_w2v_path(W2V_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size : 100000\n"
     ]
    }
   ],
   "source": [
    "# Load embeddings of K most frequent words\n",
    "model.build_vocab_k_words(K=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "443"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of article sentences to be encoded:\n",
    "len(article_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode sentences\n",
    "* CPU Speed: ~100 sentences/sec\n",
    "* GPU Speed: ~1000 sentences/sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb words kept : 7300/11310 (64.5%)\n",
      "Speed : 49.9 sentences/s (cpu mode, bsize=128)\n",
      "nb sentences encoded : 443\n"
     ]
    }
   ],
   "source": [
    "embeddings = model.encode(article_sentences, bsize=128, tokenize=False, verbose=True)\n",
    "print('nb sentences encoded : {0}'.format(len(embeddings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09396838, 0.07308353, 0.04056723, ..., 0.01159299, 0.        ,\n",
       "        0.05563534],\n",
       "       [0.04758248, 0.03204281, 0.04894754, ..., 0.00389264, 0.        ,\n",
       "        0.02934591]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(443, 4096)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring cosine similarity between any 2 sentences in the article\n",
    "Note: model.visualize(article_sentences[randint(0, len(article_sentences))]) throws an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(u, v):\n",
    "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
    "\n",
    "def euclidean_dist(u, v):\n",
    "    return math.sqrt(sum([(a - b) ** 2 for a, b in zip(u, v)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1:\n",
      "Coastal features include the marshy Rann of Kutch of western India and the alluvial Sundarbans delta of eastern India; the latter is shared with Bangladesh.\n",
      "\n",
      "Sentence 2:\n",
      "Constituted in such fashion, India lies to the north of the equator between 6° 44′ and 35° 30′ north latitude and 68° 7′ and 97° 25′ east longitude.\n",
      "\n",
      "Cosine similarity = 0.857245683670044\n",
      "Euclidean Distance = 2.879567688290825\n"
     ]
    }
   ],
   "source": [
    "random_sent1 = article_sentences[randint(0, len(article_sentences))]\n",
    "random_sent2 = article_sentences[randint(0, len(article_sentences))]\n",
    "\n",
    "cosine_sim = cosine(model.encode([random_sent1])[0], model.encode([random_sent2])[0])\n",
    "euclidean_d_value = euclidean_dist(model.encode([random_sent1])[0], model.encode([random_sent2])[0])\n",
    "\n",
    "print(\"Sentence 1:\\n{0}\\n\\nSentence 2:\\n{1}\\n\".format(random_sent1, random_sent2))\n",
    "print(\"Cosine similarity = {0}\\nEuclidean Distance = {1}\".format(cosine_sim, euclidean_d_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Vector Approach - Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_similar_sentences(question_vector, sent_count):\n",
    "    \"\"\"Returns the most similar sentences to the question vector.\n",
    "    Similarity Coefficient used: Cosine Index\n",
    "    Sentence count refers to number of most similar sentences to be returned.\n",
    "    \"\"\"\n",
    "    most_sim_sentences = []\n",
    "    for sent_index, sent_vector in enumerate(embeddings):\n",
    "        most_sim_sentences.append((sent_index, cosine(question_vector, sent_vector))) # appending a tuple\n",
    "    most_sim_sentences.sort(key = lambda x: x[1], reverse = True)\n",
    "    if sent_count <= len(embeddings):\n",
    "        return most_sim_sentences[:sent_count]\n",
    "    else:\n",
    "        return most_sim_sentences[:len(embeddings)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb words kept : 5/9 (55.6%)\n",
      "Speed : 25.7 sentences/s (cpu mode, bsize=128)\n",
      "Question vector: [ 0.04600282  0.15134372 -0.04607344 ...  0.0321859  -0.02943331\n",
      "  0.05108219]\n",
      "nb sentences encoded : 1\n"
     ]
    }
   ],
   "source": [
    "question = 'Which are the neighbouring countries to India?'\n",
    "question = [question]\n",
    "question_vector = model.encode(question, bsize=128, tokenize=False, verbose=True)[0]\n",
    "print('Question vector: {0}'.format(question_vector))\n",
    "print('nb sentences encoded : {0}'.format(len(question)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get 5 most similar sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(76, 0.8174522), (265, 0.81478786), (204, 0.8145509), (291, 0.8134547), (440, 0.8075874)]\n"
     ]
    }
   ],
   "source": [
    "most_sim_sentences = get_most_similar_sentences(question_vector, 5)\n",
    "print(most_sim_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the most similar sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Index 76, Similarity Score = 0.8174521923065186:\n",
      "They were imitated all over India and led to both the resurgence of Hinduism and the development of all modern languages of the subcontinent.\n",
      "\n",
      "Sentence Index 265, Similarity Score = 0.8147878646850586:\n",
      "However, it has remained lower than those of other Asian developing countries like Indonesia, Malaysia, Philippines, Sri Lanka, and Thailand, and is expected to remain so in the near future.\n",
      "\n",
      "Sentence Index 204, Similarity Score = 0.8145508766174316:\n",
      "All states, as well as the union territories of Jammu and Kashmir, Puducherry and the National Capital Territory of Delhi, have elected legislatures and governments following the Westminster system of governance.\n",
      "\n",
      "Sentence Index 291, Similarity Score = 0.8134546875953674:\n",
      "Corruption in India is perceived to have decreased.\n",
      "\n",
      "Sentence Index 440, Similarity Score = 0.8075873851776123:\n",
      "India has traditionally been the dominant country at the South Asian Games.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent_index, similarity_score in most_sim_sentences:\n",
    "    print('Sentence Index {}, Similarity Score = {}:\\n{}\\n'.format(sent_index, similarity_score,\n",
    "                                                                        article_sentences[sent_index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb words kept : 2/7 (28.6%)\n",
      "Speed : 55.7 sentences/s (cpu mode, bsize=128)\n",
      "Question vector: [ 0.12260894 -0.02809364 -0.06930935 ... -0.04209305 -0.0116544\n",
      " -0.00440081]\n",
      "nb sentences encoded : 1\n"
     ]
    }
   ],
   "source": [
    "question = 'Which sports does India play?'\n",
    "question = [question]\n",
    "question_vector = model.encode(question, bsize=128, tokenize=False, verbose=True)[0]\n",
    "print('Question vector: {0}'.format(question_vector))\n",
    "print('nb sentences encoded : {0}'.format(len(question)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Index 435, Similarity Score = 0.6431796550750732:\n",
      "Cricket is the most popular sport in India.\n",
      "\n",
      "Sentence Index 427, Similarity Score = 0.6050891280174255:\n",
      "In India, several traditional indigenous sports remain fairly popular, such as kabaddi, kho kho, pehlwani and gilli-danda.\n",
      "\n",
      "Sentence Index 440, Similarity Score = 0.6028776168823242:\n",
      "India has traditionally been the dominant country at the South Asian Games.\n",
      "\n",
      "Sentence Index 291, Similarity Score = 0.5923976898193359:\n",
      "Corruption in India is perceived to have decreased.\n",
      "\n",
      "Sentence Index 433, Similarity Score = 0.5900624990463257:\n",
      "Other sports in which Indians have succeeded internationally include badminton (Saina Nehwal and P V Sindhu are two of the top-ranked female badminton players in the world), boxing, and wrestling.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "most_sim_sentences = get_most_similar_sentences(question_vector, 5)\n",
    "for sent_index, similarity_score in most_sim_sentences:\n",
    "    print('Sentence Index {}, Similarity Score = {}:\\n{}\\n'.format(sent_index, similarity_score,\n",
    "                                                                        article_sentences[sent_index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb words kept : 5/12 (41.7%)\n",
      "Speed : 24.5 sentences/s (cpu mode, bsize=128)\n",
      "Question vector: [ 0.09767815  0.07293532 -0.00092746 ...  0.00389264 -0.03927635\n",
      "  0.02507453]\n",
      "nb sentences encoded : 1\n"
     ]
    }
   ],
   "source": [
    "question = 'Approximately how many Indians served in the First World War?'\n",
    "question = [question]\n",
    "question_vector = model.encode(question, bsize=128, tokenize=False, verbose=True)[0]\n",
    "print('Question vector: {0}'.format(question_vector))\n",
    "print('nb sentences encoded : {0}'.format(len(question)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Index 440, Similarity Score = 0.846401572227478:\n",
      "India has traditionally been the dominant country at the South Asian Games.\n",
      "\n",
      "Sentence Index 204, Similarity Score = 0.8330858945846558:\n",
      "All states, as well as the union territories of Jammu and Kashmir, Puducherry and the National Capital Territory of Delhi, have elected legislatures and governments following the Westminster system of governance.\n",
      "\n",
      "Sentence Index 335, Similarity Score = 0.8261755704879761:\n",
      "In the 20th century, Indian literature was influenced by the works of the Bengali poet and novelist Rabindranath Tagore, who was a recipient of the Nobel Prize in Literature.\n",
      "\n",
      "Sentence Index 215, Similarity Score = 0.8248085975646973:\n",
      "In recent years, it has played key roles in the South Asian Association for Regional Cooperation and the World Trade Organization.\n",
      "\n",
      "Sentence Index 76, Similarity Score = 0.82387375831604:\n",
      "They were imitated all over India and led to both the resurgence of Hinduism and the development of all modern languages of the subcontinent.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "most_sim_sentences = get_most_similar_sentences(question_vector, 5)\n",
    "for sent_index, similarity_score in most_sim_sentences:\n",
    "    print('Sentence Index {}, Similarity Score = {}:\\n{}\\n'.format(sent_index, similarity_score,\n",
    "                                                                        article_sentences[sent_index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb words kept : 5/10 (50.0%)\n",
      "Speed : 24.5 sentences/s (cpu mode, bsize=128)\n",
      "Question vector: [ 0.08511851  0.03973034  0.07982003 ...  0.00812555 -0.02943331\n",
      "  0.00681409]\n",
      "nb sentences encoded : 1\n"
     ]
    }
   ],
   "source": [
    "question = \"What did the greek refer to Indians as?\"\n",
    "question = [question]\n",
    "question_vector = model.encode(question, bsize=128, tokenize=False, verbose=True)[0]\n",
    "print('Question vector: {0}'.format(question_vector))\n",
    "print('nb sentences encoded : {0}'.format(len(question)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Index 65, Similarity Score = 0.7895320057868958:\n",
      "Under the Guptas, a renewed Hinduism based on devotion, rather than the management of ritual, began to assert itself.\n",
      "\n",
      "Sentence Index 189, Similarity Score = 0.781525194644928:\n",
      "In 1998, the BJP was able to form a successful coalition, the National Democratic Alliance (NDA).\n",
      "\n",
      "Sentence Index 88, Similarity Score = 0.7803148031234741:\n",
      "The resulting Mughal Empire did not stamp out the local societies it came to rule.\n",
      "\n",
      "Sentence Index 38, Similarity Score = 0.7792684435844421:\n",
      "The ancient Greeks referred to the Indians as Indoi (Ἰνδοί), which translates as \"The people of the Indus\".\n",
      "\n",
      "Sentence Index 335, Similarity Score = 0.7666915059089661:\n",
      "In the 20th century, Indian literature was influenced by the works of the Bengali poet and novelist Rabindranath Tagore, who was a recipient of the Nobel Prize in Literature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "most_sim_sentences = get_most_similar_sentences(question_vector, 5)\n",
    "for sent_index, similarity_score in most_sim_sentences:\n",
    "    print('Sentence Index {}, Similarity Score = {}:\\n{}\\n'.format(sent_index, similarity_score,\n",
    "                                                                        article_sentences[sent_index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation - Single Vector - Cosine Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these functions are heavily influenced by the HF squad_metrics.py script\n",
    "def normalize_text(s):\n",
    "    \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
    "    import string, re\n",
    "\n",
    "    def remove_articles(text):\n",
    "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "        return re.sub(regex, \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def compute_exact_match(prediction, truth):\n",
    "    return int(normalize_text(prediction) == normalize_text(truth))\n",
    "\n",
    "def compute_f1(prediction, truth):\n",
    "    pred_tokens = normalize_text(prediction).split()\n",
    "    truth_tokens = normalize_text(truth).split()\n",
    "    #print(pred_tokens)\n",
    "    #print(truth_tokens)\n",
    "    \n",
    "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
    "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
    "        return int(pred_tokens == truth_tokens)\n",
    "    \n",
    "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
    "    \n",
    "    # if there are no common tokens then f1 = 0\n",
    "    if len(common_tokens) == 0:\n",
    "        return 0\n",
    "    #print(common_tokens)\n",
    "    prec = len(common_tokens) / len(pred_tokens)\n",
    "    rec = len(common_tokens) / len(truth_tokens)\n",
    "    \n",
    "    return 2 * (prec * rec) / (prec + rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('val_questions.json', 'r') as fp:\n",
    "    val_questions = json.load(fp)\n",
    "    \n",
    "with open('val_answers.json', 'r') as fp:\n",
    "    val_answers = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pred_answers = dict()\n",
    "for qid, question in val_questions.items():\n",
    "    question = [question]\n",
    "    question_vector = model.encode(question, bsize=128, tokenize=False, verbose=True)[0]\n",
    "    most_sim_sentences = get_most_similar_sentences(question_vector, 5)\n",
    "    # Consider the first most similar as the predicted answer for the qid.\n",
    "    pred_answer_index = most_sim_sentences[0][0]\n",
    "    pred_answers[qid] = article_sentences[pred_answer_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving predictions\n",
    "with open('infersent_glove_single_vector_cosine_pred_answers.json', 'w') as fp:\n",
    "    json.dump(pred_answers, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Avg F1 Score: 0.6797236977138025\n",
      "\n",
      "Avg EM Score: 0.68\n"
     ]
    }
   ],
   "source": [
    "f1_scores = []\n",
    "em_scores = []\n",
    "\n",
    "for qid, pred_ans in pred_answers.items():\n",
    "    true_ans = val_answers[qid]\n",
    "    f1_score = compute_f1(pred_ans, true_ans)\n",
    "    em_score = compute_exact_match(pred_ans, true_ans)\n",
    "    \n",
    "    f1_scores.append(f1_score)\n",
    "    em_scores.append(em_score)\n",
    "\n",
    "avg_f1 = sum(f1_scores) / len(f1_scores)\n",
    "avg_em = sum(em_scores) / len(em_scores)\n",
    "\n",
    "print('\\nAvg F1 Score: {}'.format(avg_f1))\n",
    "print('\\nAvg EM Score: {}'.format(avg_em))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------- Single Vector - Euclidean Distance ---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_similar_sentences_euclidean(question_vector, sent_count):\n",
    "    \"\"\"Returns the most similar sentences to the question vector.\n",
    "    Similarity Coefficient used: Euclidean Distance\n",
    "    Sentence count refers to number of most similar sentences to be returned.\n",
    "    \"\"\"\n",
    "    most_sim_sentences = []\n",
    "    for sent_index, sent_vector in enumerate(embeddings):\n",
    "        most_sim_sentences.append((sent_index, euclidean_dist(question_vector, sent_vector))) # appending a tuple\n",
    "    most_sim_sentences.sort(key = lambda x: x[1], reverse = False) # sort direction = ascending\n",
    "    if sent_count <= len(embeddings):\n",
    "        return most_sim_sentences[:sent_count]\n",
    "    else:\n",
    "        print('Enter value less than or equal to {0}'.format(len(embeddings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb words kept : 5/9 (55.6%)\n",
      "Speed : 25.7 sentences/s (cpu mode, bsize=128)\n",
      "Question vector: [ 0.04600282  0.15134372 -0.04607344 ...  0.0321859  -0.02943331\n",
      "  0.05108219]\n",
      "nb sentences encoded : 1\n"
     ]
    }
   ],
   "source": [
    "question = 'Which are the neighbouring countries to India?'\n",
    "question = [question]\n",
    "question_vector = model.encode(question, bsize=128, tokenize=False, verbose=True)[0]\n",
    "print('Question vector: {0}'.format(question_vector))\n",
    "print('nb sentences encoded : {0}'.format(len(question)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(291, 2.616865479370186), (440, 2.807772790459424), (231, 2.81859848188907), (105, 2.8372004735565755), (0, 2.867852769122867)]\n"
     ]
    }
   ],
   "source": [
    "most_sim_sentences = get_most_similar_sentences_euclidean(question_vector, 5) # note the 2\n",
    "print(most_sim_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Sentence Index 291, Similarity Score = 2.616865479370186:\n",
      "Corruption in India is perceived to have decreased.\n",
      "\n",
      "2. Sentence Index 440, Similarity Score = 2.807772790459424:\n",
      "India has traditionally been the dominant country at the South Asian Games.\n",
      "\n",
      "3. Sentence Index 231, Similarity Score = 2.81859848188907:\n",
      "It comprises the Indian Army, the Indian Navy, the Indian Air Force, and the Indian Coast Guard.\n",
      "\n",
      "4. Sentence Index 105, Similarity Score = 2.8372004735565755:\n",
      "Technological changes—among them, railways, canals, and the telegraph—were introduced not long after their introduction in Europe.\n",
      "\n",
      "5. Sentence Index 0, Similarity Score = 2.867852769122867:\n",
      "India (Hindi: Bhārat), officially the Republic of India (Hindi: Bhārat Gaṇarājya), is a country in South Asia.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for sent_index, similarity_score in most_sim_sentences:\n",
    "    i += 1\n",
    "    print('{}. Sentence Index {}, Similarity Score = {}:\\n{}\\n'.format(i, sent_index, similarity_score,\n",
    "                                                                        article_sentences[sent_index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('val_questions.json', 'r') as fp:\n",
    "    val_questions = json.load(fp)\n",
    "    \n",
    "with open('val_answers.json', 'r') as fp:\n",
    "    val_answers = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb words kept : 1/5 (20.0%)\n",
      "Speed : 100.7 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 6/11 (54.5%)\n",
      "Speed : 23.3 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 11/16 (68.8%)\n",
      "Speed : 14.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 11/15 (73.3%)\n",
      "Speed : 13.2 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 12/20 (60.0%)\n",
      "Speed : 12.2 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 6/11 (54.5%)\n",
      "Speed : 24.5 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 3/8 (37.5%)\n",
      "Speed : 43.7 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 14/18 (77.8%)\n",
      "Speed : 10.8 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 19/26 (73.1%)\n",
      "Speed : 8.2 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 7/14 (50.0%)\n",
      "Speed : 13.4 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 10/14 (71.4%)\n",
      "Speed : 15.7 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 14/19 (73.7%)\n",
      "Speed : 11.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 4/10 (40.0%)\n",
      "Speed : 35.8 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 10/17 (58.8%)\n",
      "Speed : 15.0 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 15/25 (60.0%)\n",
      "Speed : 10.6 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 11/17 (64.7%)\n",
      "Speed : 13.0 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 8/14 (57.1%)\n",
      "Speed : 18.6 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 8/18 (44.4%)\n",
      "Speed : 18.6 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 8/13 (61.5%)\n",
      "Speed : 17.6 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 10/14 (71.4%)\n",
      "Speed : 15.7 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 12/18 (66.7%)\n",
      "Speed : 12.9 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 14/19 (73.7%)\n",
      "Speed : 11.3 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 12/17 (70.6%)\n",
      "Speed : 12.9 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 6/11 (54.5%)\n",
      "Speed : 24.5 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 5/11 (45.5%)\n",
      "Speed : 23.3 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 8/13 (61.5%)\n",
      "Speed : 18.6 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 11/17 (64.7%)\n",
      "Speed : 14.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 2/8 (25.0%)\n",
      "Speed : 66.8 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 7/13 (53.8%)\n",
      "Speed : 21.3 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 8/15 (53.3%)\n",
      "Speed : 18.6 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 5/10 (50.0%)\n",
      "Speed : 28.6 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 7/11 (63.6%)\n",
      "Speed : 21.8 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 10/15 (66.7%)\n",
      "Speed : 14.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 7/11 (63.6%)\n",
      "Speed : 20.5 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 4/10 (40.0%)\n",
      "Speed : 35.9 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 6/12 (50.0%)\n",
      "Speed : 25.7 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 7/14 (50.0%)\n",
      "Speed : 20.9 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 3/8 (37.5%)\n",
      "Speed : 47.7 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 7/12 (58.3%)\n",
      "Speed : 20.9 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 15/19 (78.9%)\n",
      "Speed : 10.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 11/16 (68.8%)\n",
      "Speed : 14.3 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 10/15 (66.7%)\n",
      "Speed : 14.8 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 10/15 (66.7%)\n",
      "Speed : 15.2 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 4/9 (44.4%)\n",
      "Speed : 35.9 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 6/10 (60.0%)\n",
      "Speed : 25.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 7/12 (58.3%)\n",
      "Speed : 17.0 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 10/15 (66.7%)\n",
      "Speed : 15.2 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 16/20 (80.0%)\n",
      "Speed : 9.2 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 10/18 (55.6%)\n",
      "Speed : 14.3 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 12/17 (70.6%)\n",
      "Speed : 12.9 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 12/17 (70.6%)\n",
      "Speed : 12.8 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 9/14 (64.3%)\n",
      "Speed : 17.3 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 9/13 (69.2%)\n",
      "Speed : 16.7 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 10/15 (66.7%)\n",
      "Speed : 15.2 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 6/11 (54.5%)\n",
      "Speed : 25.7 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 14/18 (77.8%)\n",
      "Speed : 10.4 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 2/7 (28.6%)\n",
      "Speed : 62.7 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 10/19 (52.6%)\n",
      "Speed : 15.0 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 8/12 (66.7%)\n",
      "Speed : 18.6 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 12/18 (66.7%)\n",
      "Speed : 12.7 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 8/15 (53.3%)\n",
      "Speed : 17.6 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 15/20 (75.0%)\n",
      "Speed : 10.6 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 12/20 (60.0%)\n",
      "Speed : 12.4 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 8/12 (66.7%)\n",
      "Speed : 15.2 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 10/17 (58.8%)\n",
      "Speed : 15.2 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 14/20 (70.0%)\n",
      "Speed : 10.8 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 12/17 (70.6%)\n",
      "Speed : 13.2 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 3/8 (37.5%)\n",
      "Speed : 28.6 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 7/12 (58.3%)\n",
      "Speed : 21.8 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 7/14 (50.0%)\n",
      "Speed : 18.9 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 18/23 (78.3%)\n",
      "Speed : 8.5 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 4/11 (36.4%)\n",
      "Speed : 37.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 7/12 (58.3%)\n",
      "Speed : 20.9 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 6/10 (60.0%)\n",
      "Speed : 24.5 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 14/19 (73.7%)\n",
      "Speed : 10.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 7/13 (53.8%)\n",
      "Speed : 8.6 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 9/14 (64.3%)\n",
      "Speed : 17.0 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 6/10 (60.0%)\n",
      "Speed : 22.8 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 7/12 (58.3%)\n",
      "Speed : 20.9 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 8/15 (53.3%)\n",
      "Speed : 12.4 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 5/9 (55.6%)\n",
      "Speed : 27.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 6/12 (50.0%)\n",
      "Speed : 24.5 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 11/16 (68.8%)\n",
      "Speed : 13.4 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 4/9 (44.4%)\n",
      "Speed : 37.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 9/13 (69.2%)\n",
      "Speed : 17.3 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 14/19 (73.7%)\n",
      "Speed : 10.3 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 10/16 (62.5%)\n",
      "Speed : 15.7 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 11/17 (64.7%)\n",
      "Speed : 14.5 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 4/10 (40.0%)\n",
      "Speed : 23.9 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 6/11 (54.5%)\n",
      "Speed : 23.9 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 16/20 (80.0%)\n",
      "Speed : 9.6 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 9/15 (60.0%)\n",
      "Speed : 15.2 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 5/12 (41.7%)\n",
      "Speed : 30.3 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 11/15 (73.3%)\n",
      "Speed : 14.5 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 7/11 (63.6%)\n",
      "Speed : 21.8 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 18/24 (75.0%)\n",
      "Speed : 8.8 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 1/5 (20.0%)\n",
      "Speed : 111.4 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 10/14 (71.4%)\n",
      "Speed : 14.7 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 15/23 (65.2%)\n",
      "Speed : 10.7 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 10/15 (66.7%)\n",
      "Speed : 15.2 sentences/s (cpu mode, bsize=128)\n"
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "pred_answers_euclidean = dict()\n",
    "for qid, question in val_questions.items():\n",
    "    question = [question]\n",
    "    question_vector = model.encode(question, bsize=128, tokenize=False, verbose=True)[0]\n",
    "    most_sim_sentences = get_most_similar_sentences_euclidean(question_vector, 5) #notice euclidean\n",
    "    # Consider the first most similar as the predicted answer for the qid.\n",
    "    pred_answer_index = most_sim_sentences[0][0]\n",
    "    pred_answers_euclidean[qid] = article_sentences[pred_answer_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving predictions\n",
    "with open('infersent_glove_single_vector_euclidean_pred_answers.json', 'w') as fp:\n",
    "    json.dump(pred_answers_euclidean, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Avg F1 Score: 0.6005474560255606\n",
      "\n",
      "Avg EM Score: 0.59\n"
     ]
    }
   ],
   "source": [
    "f1_scores = []\n",
    "em_scores = []\n",
    "\n",
    "for qid, pred_ans in pred_answers_euclidean.items():\n",
    "    true_ans = val_answers[qid]\n",
    "    f1_score = compute_f1(pred_ans, true_ans)\n",
    "    em_score = compute_exact_match(pred_ans, true_ans)\n",
    "    \n",
    "    f1_scores.append(f1_score)\n",
    "    em_scores.append(em_score)\n",
    "\n",
    "avg_f1 = sum(f1_scores) / len(f1_scores)\n",
    "avg_em = sum(em_scores) / len(em_scores)\n",
    "\n",
    "print('\\nAvg F1 Score: {}'.format(avg_f1))\n",
    "print('\\nAvg EM Score: {}'.format(avg_em))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
