{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline gensim word2vec and doc2vec models:\n",
    "**Without using any pre-trained embeddings and trained only on the article text.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import time\n",
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import urllib.request\n",
    "import nltk\n",
    "import re\n",
    "import heapq\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    \"\"\"Convert each sentence into lower case. \n",
    "    Extract English alphabets.\n",
    "    Remove extra spaces.\n",
    "    Strip leading/trailing whitespaces.\n",
    "    Tokenize the sentence into word_tokens to generate \"corpus\" (a list of lists).\n",
    "    \"\"\"\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(r'[^A-Za-z]', ' ', sentence)\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/India'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape article using bs4 to extract all paragraphs from the online article.\n",
    "raw_html = urllib.request.urlopen(url)\n",
    "raw_html = raw_html.read()\n",
    "\n",
    "article_html = BeautifulSoup(raw_html, 'lxml')\n",
    "article_paragraphs = article_html.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a document 'article_text' containing all the sentences in the article.\n",
    "article_text = ''\n",
    "for para in article_paragraphs:\n",
    "    article_text += para.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize article text into sentences.\n",
    "article_sentences = nltk.sent_tokenize(article_text)\n",
    "\n",
    "initial_article_sentences = nltk.sent_tokenize(article_text)\n",
    "for i in range(len(initial_article_sentences)):\n",
    "    initial_article_sentences[i] = re.sub(r'\\[\\d+\\]', '', initial_article_sentences[i])\n",
    "    initial_article_sentences[i] = re.sub(r'\\[\\d+,\\s\\d+]', '', initial_article_sentences[i])\n",
    "    initial_article_sentences[i] = re.sub(r'\\[\\w\\]', '', initial_article_sentences[i])\n",
    "    initial_article_sentences[i] = re.sub(r'\\s+', ' ', initial_article_sentences[i]).strip()\n",
    "\n",
    "corpus = []\n",
    "for i in range(len(article_sentences)):\n",
    "    article_sentences[i] = clean_sentence(article_sentences[i])\n",
    "    corpus.append(nltk.word_tokenize(article_sentences[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "for i in range(len(corpus)):\n",
    "    corpus[i] = [word for word in corpus[i] if word not in stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2vec: Word Embeddings\n",
    "Exploring performance at the word level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### min_count = 2\n",
    "A value of 2 for min_count specifies to include only those words in the Word2Vec model that appear at least twice in the corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model1 = Word2Vec(corpus, min_count=2)\n",
    "vocabulary = word2vec_model1.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'india': <gensim.models.keyedvectors.Vocab at 0x257be630708>,\n",
       " 'hindi': <gensim.models.keyedvectors.Vocab at 0x257be630088>,\n",
       " 'bh': <gensim.models.keyedvectors.Vocab at 0x257be630148>,\n",
       " 'rat': <gensim.models.keyedvectors.Vocab at 0x257be630248>,\n",
       " 'republic': <gensim.models.keyedvectors.Vocab at 0x257bf8feec8>}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(vocabulary))\n",
    "dict(itertools.islice(vocabulary.items(), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('indian', 0.5979833006858826),\n",
       " ('population', 0.4569549858570099),\n",
       " ('also', 0.42163097858428955),\n",
       " ('worn', 0.3961172103881836),\n",
       " ('economy', 0.3931373059749603),\n",
       " ('women', 0.3902481198310852),\n",
       " ('support', 0.3874567151069641),\n",
       " ('country', 0.3836236596107483),\n",
       " ('us', 0.3788153827190399),\n",
       " ('company', 0.36064597964286804)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model1.wv.most_similar('india')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tiger', 0.2946946918964386),\n",
       " ('identification', 0.29314494132995605),\n",
       " ('felt', 0.27995747327804565),\n",
       " ('caused', 0.25238704681396484),\n",
       " ('effects', 0.24596229195594788),\n",
       " ('plate', 0.24509194493293762),\n",
       " ('rule', 0.2178593873977661),\n",
       " ('influence', 0.2160549759864807),\n",
       " ('ancient', 0.2153869867324829),\n",
       " ('andhra', 0.2146497368812561)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model1.wv.most_similar('river')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### min_count = 5\n",
    "Train model with words which appear at least 5 times in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model2 = Word2Vec(corpus, min_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('indian', 0.681346595287323),\n",
       " ('kameez', 0.5191697478294373),\n",
       " ('women', 0.509523868560791),\n",
       " ('company', 0.5089674592018127),\n",
       " ('mughal', 0.4884563386440277),\n",
       " ('economy', 0.47067099809646606),\n",
       " ('many', 0.4629589915275574),\n",
       " ('million', 0.45229029655456543),\n",
       " ('southern', 0.44202178716659546),\n",
       " ('used', 0.43884631991386414)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model2.wv.most_similar('india')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('caused', 0.31095075607299805),\n",
       " ('rule', 0.2795999050140381),\n",
       " ('ancient', 0.2776738405227661),\n",
       " ('asian', 0.2737332880496979),\n",
       " ('plate', 0.2706279456615448),\n",
       " ('ce', 0.26471376419067383),\n",
       " ('gdp', 0.2511984705924988),\n",
       " ('census', 0.24155351519584656),\n",
       " ('market', 0.2413475513458252),\n",
       " ('classical', 0.23530247807502747)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model2.wv.most_similar('river')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2vec: Sentence Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a tagged corpus as training data to the doc2vec model i.e. each corpus list (containing the tokens of the sentence) is tagged with an integer ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_corpus = [TaggedDocument(d, [i]) for i, d in enumerate(corpus)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training word2vec on tagged corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_model = Doc2Vec(tagged_corpus, vector_size=20, window=2, min_count=1, workers=4, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peeking at the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'india': <gensim.models.keyedvectors.Vocab at 0x257bcf5d0c8>,\n",
       " 'hindi': <gensim.models.keyedvectors.Vocab at 0x257bcf5d248>,\n",
       " 'bh': <gensim.models.keyedvectors.Vocab at 0x257bcf5d408>,\n",
       " 'rat': <gensim.models.keyedvectors.Vocab at 0x257bcf5d4c8>,\n",
       " 'officially': <gensim.models.keyedvectors.Vocab at 0x257bcf5d708>,\n",
       " 'republic': <gensim.models.keyedvectors.Vocab at 0x257bcf5da48>}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vec_vocabulary = doc2vec_model.wv.vocab\n",
    "dict(itertools.islice(doc2vec_vocabulary.items(), 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to display the top-N most similar sentences w.r.t. the question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_similar_sentences(question):\n",
    "    clean_question = clean_sentence(question)\n",
    "    question_tokens = nltk.word_tokenize(clean_question)\n",
    "    question_tokens = [word for word in question_tokens if word not in stop_words]\n",
    "    \n",
    "    # most_similar() returns the tag number and the similarity score for the \"topn\" most similar sentences.\n",
    "    # The \"positive\" attribute can take a single docvec (a list of 1 array) or multiple docvecs (a list of multiple arrays)\n",
    "    # Here, one array is for a single sentence vector (or docvec)\n",
    "    # If multiple docvecs are given, it takes the mean of the vectors. \n",
    "    # Cosine similarity is computed between the mean vector and the other vectors in the training data.\n",
    "    similar_sentences = doc2vec_model.docvecs.most_similar(positive=[doc2vec_model.infer_vector(question_tokens)], topn=5)\n",
    "    \n",
    "    print(\"Question:\\n{0}\".format(question))\n",
    "    print(\"Question tokens considered: {0}\\n\".format(question_tokens))\n",
    "    print(\"Similar Sentences:\\n\")\n",
    "    \n",
    "    for i, sent in enumerate(similar_sentences):\n",
    "        sentence = initial_article_sentences[sent[0]]\n",
    "        sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "        sentence = re.sub(r'\\[\\d+\\]','' , sentence).strip()\n",
    "        print(\"Sentence {0}: (Similarity Score = {1})\".format(i+1, sent[1]))\n",
    "        print(sentence, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Where is India located?\n",
      "Question tokens considered: ['india', 'located']\n",
      "\n",
      "Similar Sentences:\n",
      "\n",
      "Sentence 1: (Similarity Score = 0.922821044921875)\n",
      "It predominates in the tropical moist forest of the Andaman Islands, the Western Ghats, and Northeast India. \n",
      "\n",
      "Sentence 2: (Similarity Score = 0.912075400352478)\n",
      "India has two archipelagos: the Lakshadweep, coral atolls off India's south-western coast; and the Andaman and Nicobar Islands, a volcanic chain in the Andaman Sea. \n",
      "\n",
      "Sentence 3: (Similarity Score = 0.912002444267273)\n",
      "[j] India's forest cover is 701,673 km2 (270,917 sq mi), which is 21.35% of the country's total land area. \n",
      "\n",
      "Sentence 4: (Similarity Score = 0.9063073396682739)\n",
      "It predominates in the temperate coniferous forest of the Himalayas, the moist deciduous sal forest of eastern India, and the dry deciduous teak forest of central and southern India. \n",
      "\n",
      "Sentence 5: (Similarity Score = 0.9052748680114746)\n",
      "India has traditionally been the dominant country at the South Asian Games. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = 'Where is India located?'\n",
    "show_similar_sentences(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Which are the neighbouring countries to India?\n",
      "Question tokens considered: ['neighbouring', 'countries', 'india']\n",
      "\n",
      "Similar Sentences:\n",
      "\n",
      "Sentence 1: (Similarity Score = 0.882215142250061)\n",
      "After initially cordial relations with neighbouring China, India went to war with China in 1962, and was widely thought to have been humiliated. \n",
      "\n",
      "Sentence 2: (Similarity Score = 0.8802105188369751)\n",
      "India also contains four of the world's 34 biodiversity hotspots, or regions that display significant habitat loss in the presence of high endemism. \n",
      "\n",
      "Sentence 3: (Similarity Score = 0.8722947835922241)\n",
      "It has disputes over Kashmir with its neighbours, Pakistan and China, unresolved since the mid-20th century. \n",
      "\n",
      "Sentence 4: (Similarity Score = 0.8674148321151733)\n",
      "India is the world's most populous democracy. \n",
      "\n",
      "Sentence 5: (Similarity Score = 0.8655755519866943)\n",
      "It has unresolved territorial disputes with China and with Pakistan. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"Which are the neighbouring countries to India?\"\n",
    "show_similar_sentences(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Which sports does India play?\n",
      "Question tokens considered: ['sports', 'india', 'play']\n",
      "\n",
      "Similar Sentences:\n",
      "\n",
      "Sentence 1: (Similarity Score = 0.9705215692520142)\n",
      "The World Bank cautions that, for India to achieve its economic potential, it must continue to focus on public sector reform, transport infrastructure, agricultural and rural development, removal of labour regulations, education, energy security, and public health and nutrition. \n",
      "\n",
      "Sentence 2: (Similarity Score = 0.9698085188865662)\n",
      "These included the consolidation and demarcation of sovereignty, the surveillance of the population, and the education of citizens. \n",
      "\n",
      "Sentence 3: (Similarity Score = 0.9696745276451111)\n",
      "India has a comparatively strong presence in shooting sports, and has won several medals at the Olympics, the World Shooting Championships, and the Commonwealth Games. \n",
      "\n",
      "Sentence 4: (Similarity Score = 0.9696272611618042)\n",
      "Among the socio-economic challenges India faces are gender inequality, child malnutrition, and rising levels of air pollution. \n",
      "\n",
      "Sentence 5: (Similarity Score = 0.9680058360099792)\n",
      "India's sustained democratic freedoms are unique among the world's newer nations; however, in spite of its recent economic successes, freedom from want for its disadvantaged population remains a goal yet to be achieved. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"Which sports does India play?\"\n",
    "show_similar_sentences(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "What did the greek refer to Indians as?\n",
      "Question tokens considered: ['greek', 'refer', 'indians']\n",
      "\n",
      "Similar Sentences:\n",
      "\n",
      "Sentence 1: (Similarity Score = 0.9536331295967102)\n",
      "However, barely 2% of Indians pay income taxes. \n",
      "\n",
      "Sentence 2: (Similarity Score = 0.9433398246765137)\n",
      "The ancient Greeks referred to the Indians as Indoi (Ἰνδοί), which translates as \"The people of the Indus\". \n",
      "\n",
      "Sentence 3: (Similarity Score = 0.935443639755249)\n",
      "There are around 50 physicians per 100,000 Indians. \n",
      "\n",
      "Sentence 4: (Similarity Score = 0.9347553253173828)\n",
      "The human sex ratio, according to the 2011 census, is 940 females per 1,000 males. \n",
      "\n",
      "Sentence 5: (Similarity Score = 0.931684136390686)\n",
      "An overwhelming majority of Indians, with their consent, have their marriages arranged by their parents or other family elders. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"What did the greek refer to Indians as?\"\n",
    "show_similar_sentences(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Approximately how many Indians served in the First World War?\n",
      "Question tokens considered: ['approximately', 'many', 'indians', 'served', 'first', 'world', 'war']\n",
      "\n",
      "Similar Sentences:\n",
      "\n",
      "Sentence 1: (Similarity Score = 0.79473477602005)\n",
      "Some 431 million Indians have left poverty since 1985; India's middle classes are projected to number around 580 million by 2030. \n",
      "\n",
      "Sentence 2: (Similarity Score = 0.7896140217781067)\n",
      "According to the 2011 census, there were 10.1 million child labourers in the country, a decline of 2.6 million from 12.6 million in 2001. \n",
      "\n",
      "Sentence 3: (Similarity Score = 0.7694747447967529)\n",
      "According to a 2016 Walk Free Foundation report there were an estimated 18.3 million people in India, or 1.4% of the population, living in the forms of modern slavery, such as bonded labour, child labour, human trafficking, and forced begging, among others. \n",
      "\n",
      "Sentence 4: (Similarity Score = 0.7649405002593994)\n",
      "After World War I, in which approximately one million Indians served, a new period began. \n",
      "\n",
      "Sentence 5: (Similarity Score = 0.7637096643447876)\n",
      "India's foreign exchange remittances of US$70 billion in 2014, the largest in the world, were contributed to its economy by 25 million Indians working in foreign countries. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"Approximately how many Indians served in the First World War?\"\n",
    "show_similar_sentences(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('val_questions.json', 'r') as fp:\n",
    "    val_questions = json.load(fp)\n",
    "    \n",
    "with open('val_answers.json', 'r') as fp:\n",
    "    val_answers = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for qid, question in val_questions:\n",
    "\n",
    "    clean_question = clean_sentence(question)\n",
    "    question_tokens = nltk.word_tokenize(clean_question)\n",
    "    question_tokens = [word for word in question_tokens if word not in stop_words]\n",
    "\n",
    "    similar_sentences = doc2vec_model.docvecs.most_similar(positive=[doc2vec_model.infer_vector(question_tokens)], topn=5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_similar_sentences(question):\n",
    "    clean_question = clean_sentence(question)\n",
    "    question_tokens = nltk.word_tokenize(clean_question)\n",
    "    question_tokens = [word for word in question_tokens if word not in stop_words]\n",
    "    \n",
    "    # most_similar() returns the tag number and the similarity score for the \"topn\" most similar sentences.\n",
    "    # The \"positive\" attribute can take a single docvec (a list of 1 array) or multiple docvecs (a list of multiple arrays)\n",
    "    # Here, one array is for a single sentence vector (or docvec)\n",
    "    # If multiple docvecs are given, it takes the mean of the vectors. \n",
    "    # Cosine similarity is computed between the mean vector and the other vectors in the training data.\n",
    "    similar_sentences = doc2vec_model.docvecs.most_similar(positive=[doc2vec_model.infer_vector(question_tokens)], topn=5)\n",
    "    \n",
    "    print(\"Question:\\n{0}\".format(question))\n",
    "    print(\"Question tokens considered: {0}\\n\".format(question_tokens))\n",
    "    print(\"Similar Sentences:\\n\")\n",
    "    \n",
    "    for i, sent in enumerate(similar_sentences):\n",
    "        sentence = initial_article_sentences[sent[0]]\n",
    "        sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "        sentence = re.sub(r'\\[\\d+\\]','' , sentence).strip()\n",
    "        print(\"Sentence {0}: (Similarity Score = {1})\".format(i+1, sent[1]))\n",
    "        print(sentence, \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
